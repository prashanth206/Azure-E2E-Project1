This project showcases an end-to-end data engineering pipeline based on the Medallion Architecture.

ðŸ“Š Project Highlights

Data Ingestion: Extract data from an HTTP server and load it into SQL Server.

Incremental Data Load: Move data incrementally from SQL Server to Azure Data Lake Storage Gen2 (ADLS Gen2).

Data Transformation: Load data from ADLS Gen2 into Azure Databricks using Unity Catalog and apply data transformations.

Dimensional Modeling: Design and create Fact and Dimension tables for analytical purposes.

Pipeline Orchestration: Automate and manage data workflows using Azure Data Factory (ADF) and Databricks Workflows.

This project demonstrates best practices in data ingestion, transformation, modeling, and orchestration within the Azure ecosystem.
